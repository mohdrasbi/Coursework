{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.linear_model import (LogisticRegression, SGDClassifier, \n",
    "                                  SGDRegressor, LinearRegression)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.testing import all_estimators\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printScore(y1, y2, n):\n",
    "    print(\"Score: {:.3f}\".format(sum(y1 == y2)/n))\n",
    "    \n",
    "def predict_and_save(clf, X_test, title):\n",
    "    categories = clf.predict(X_test)\n",
    "    ids = range(16281)\n",
    "    \n",
    "    pd.DataFrame(data={\"Id\": ids, \"Category\": categories}). \\\n",
    "        to_csv(\"submission_{}.csv\".format(title), index=False)\n",
    "    \n",
    "    return categories\n",
    "\n",
    "def get_best_classifiers(X_train, y_train, X_valid, y_valid):\n",
    "    estimators = all_estimators()\n",
    "    best_clf = {}\n",
    "\n",
    "    for name, est in estimators:\n",
    "\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            if hasattr(est, 'predict'):\n",
    "                print(name)\n",
    "                clf = est().fit(X_train, y_train)\n",
    "                y_hat = clf.predict(X_valid)\n",
    "                score = printScore(y_valid, y_hat, y_hat.shape[0])\n",
    "                if score >= 0.7:\n",
    "                    best_clf[name] = est\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        print('Time taken: {}\\n'.format(time.time() - start_time))\n",
    "        \n",
    "    \n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = {\n",
    "    \"age\": None,\n",
    "    \"workclass\": [\"Private\", \"Self-emp-not-inc\", \"Self-emp-inc\", \n",
    "                  \"Federal-gov\", \"Local-gov\", \"State-gov\", \n",
    "                  \"Without-pay\", \"Never-worked\"],\n",
    "    \"fnlwgt\": None,\n",
    "    \"education\": [\"Bachelors\", \"Some-college\", \"11th\", \"HS-grad\",\n",
    "                  \"Prof-school\", \"Assoc-acdm\", \"Assoc-voc\", \"9th\",\n",
    "                  \"7th-8th\", \"12th\", \"Masters\", \"1st-4th\", \"10th\",\n",
    "                  \"Doctorate\", \"5th-6th\", \"Preschool\"],\n",
    "    \"education-num\": None,\n",
    "    \"marital-status\": [\"Married-civ-spouse\", \"Divorced\", \"Never-married\",\n",
    "                       \"Separated\", \"Widowed\", \"Married-spouse-absent\",\n",
    "                       \"Married-AF-spouse\"],\n",
    "    \"occupation\": [\"Tech-support\", \"Craft-repair\", \"Other-service\",\n",
    "                   \"Sales\", \"Exec-managerial\", \"Prof-specialty\", \n",
    "                   \"Handlers-cleaners\", \"Machine-op-inspct\", \n",
    "                   \"Adm-clerical\", \"Farming-fishing\", \"Transport-moving\",\n",
    "                   \"Priv-house-serv\", \"Protective-serv\", \"Armed-Forces\"],\n",
    "    \"relationship\": [\"Wife\", \"Own-child\", \"Husband\", \"Not-in-family\",\n",
    "                     \"Other-relative\", \"Unmarried\"],\n",
    "    \"race\": [\"White\", \"Asian-Pac-Islander\", 'Amer-Indian-Eskimo',\n",
    "             \"Other\", \"Black\"],\n",
    "    \"sex\": [\"Female\", \"Male\"],\n",
    "    \"capital-gain\": None,\n",
    "    \"capital-loss\": None,\n",
    "    \"hours-per-week\": None,\n",
    "    \"native-country\": [\"United-States\", \"Cambodia\", \"England\", \"Puerto-Rico\", \n",
    "                       \"Canada\", \"Germany\", \"Outlying-US(Guam-USVI-etc)\",\n",
    "                       \"India\", \"Japan\", \"Greece\", \"South\", \"China\",\n",
    "                       \"Cuba\", \"Iran\", \"Honduras\", \"Philippines\", \"Italy\",\n",
    "                       \"Poland\", \"Jamaica\", \"Vietnam\", \"Mexico\", \"Portugal\",\n",
    "                       \"Ireland\", \"France\", \"Dominican-Republic\", \"Laos\",\n",
    "                       \"Ecuador\", \"Taiwan\", \"Haiti\", \"Columbia\", \"Hungary\",\n",
    "                       \"Guatemala\", \"Nicaragua\", \"Scotland\", \"Thailand\",\n",
    "                       \"Yugoslavia\", \"El-Salvador\", \"Trinadad&Tobago\",\n",
    "                       \"Peru\", \"Hong\", \"Holand-Netherlands\"],\n",
    "    \"income\": None #Binary (0 means <=50K, 1 means >50K)\n",
    "}\n",
    "cols = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "       \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "       \"hours-per-week\", \"native-country\", \"income\"]\n",
    "indices = [i for i in range(15)]\n",
    "columns = {i: j for i, j in zip(indices, cols)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.data\", header=None)\n",
    "train_data = train_data.rename(columns=columns)\n",
    "train_data = train_data.apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
    "train_data = train_data.replace('?', np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/test.data\", header=None)\n",
    "test_data = test_data.rename(columns=columns)\n",
    "test_data = test_data.apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
    "test_data = test_data.replace('?', np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map strings to ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = [i for i in train_data.dtypes.index if train_data.dtypes[i] != 'int64']\n",
    "map_dict = {}\n",
    "for i in string_cols:\n",
    "    map_dict[i] = {}\n",
    "    values = attributes[i]\n",
    "    index = 0\n",
    "    for val in values:\n",
    "        map_dict[i][val] = index\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.replace(map_dict)\n",
    "train_data.fillna(train_data.mean(), inplace=True)\n",
    "\n",
    "test_data = test_data.replace(map_dict)\n",
    "test_data.fillna(test_data.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove('income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[cols]\n",
    "y = train_data['income']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "X_test = test_data[:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = log_reg.predict(X_valid)\n",
    "printScore(y_valid, y_hat, y_hat.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log_reg = predict_and_save(log_reg, X_test, \"log_reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lin_reg.predict(X_valid)\n",
    "printScore(y_valid, y_hat, y_hat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lin_reg = predict_and_save(lin_reg, X_test, \"lin_reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lin_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = sgd.predict(X_valid)\n",
    "printScore(y_valid, y_hat, y_hat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sgd = predict_and_save(sgd, X_test, \"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = forest.predict(X_valid)\n",
    "printScore(y_valid, y_hat, y_hat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = predict_and_save(forest, X_test, 'rand_forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'AdaBoostClassifier': {\n",
    "        'n_estimators': [30, 40, 50, 60, 70, 80, 90],\n",
    "        'learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 0.7, 0.8, 1.0],\n",
    "        'algorithm': ['SAMME', 'SAMME.R']\n",
    "    },\n",
    "    \n",
    "    'BaggingClassifier': {\n",
    "        'n_estimators': [5, 10, 15, 20, 30, 40, 50],\n",
    "        'max_samples': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "        'max_features': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "        'bootstrap': [True, False],\n",
    "        'bootstrap_features': [True, False]\n",
    "    },\n",
    "    \n",
    "    'BayesianGaussianMixture': {\n",
    "        'n_components': [1, 2, 4, 8, 10, 15, 20],\n",
    "        'covariance_type': ['full', 'tied', 'diag', 'spherical'],\n",
    "        'tol': [0.00001, 0.00005, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "        'reg_covar': [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01],\n",
    "        'init_params': ['kmeans', 'random']\n",
    "    },\n",
    "    \n",
    "    'BernoulliNB': {\n",
    "        'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5, 1.0],\n",
    "        'fit_prior': [True, False]\n",
    "    },\n",
    "    \n",
    "    'CalibratedClassifierCV': {\n",
    "        'method': ['sigmoid', 'isotonic'],\n",
    "        'cv': [None, 2, 3, 4, 5, 6]\n",
    "    },\n",
    "    \n",
    "    'ExtraTreeRegressor': {\n",
    "        'splitter': ['random', 'best'],\n",
    "    },\n",
    "    \n",
    "    'ExtraTreesClassifier': {\n",
    "        'n_estimators': [5, 10, 15, 20, 30, 40, 50],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    \n",
    "    'GaussianMixture': {\n",
    "        'n_components': [1, 2, 4, 8, 10, 15, 20],\n",
    "        'covariance_type': ['full', 'tied', 'diag', 'spherical'],\n",
    "        'tol': [0.00001, 0.00005, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "        'reg_covar': [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01],\n",
    "        'init_params': ['kmeans', 'random']\n",
    "    },\n",
    "    \n",
    "    'GaussianProcessRegressor': {\n",
    "        'alpha': [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 5e-3],\n",
    "        'normalize_y': [True, False]\n",
    "    },\n",
    "    \n",
    "    'GradientBoostingClassifier': {\n",
    "        'loss': ['deviance', 'exponential'],\n",
    "        'learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 0.7, 0.8, 1.0],\n",
    "        'n_estimators': [50, 70, 90, 100, 120, 140, 160],\n",
    "        'criterion': ['friedman_mse', 'mse', 'mae']\n",
    "    },\n",
    "    \n",
    "    'KNeighborsClassifier': {\n",
    "        'n_neighbors': [3, 4, 5, 7, 9, 11, 14, 16, 20],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'leaf_size': [10, 15, 20, 30, 40, 50, 60, 70],\n",
    "        'p' : [1, 2]\n",
    "    },\n",
    "    \n",
    "    'LabelPropagation': {\n",
    "        'kernel': ['knn', 'rbf'],\n",
    "        'gamma': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
    "        'n_neighbors': [3, 4, 5, 7, 10, 13, 15, 18]\n",
    "    },\n",
    "    \n",
    "    'LabelSpreading': {\n",
    "        'kernel': ['knn', 'rbf'],\n",
    "        'gamma': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
    "        'n_neighbors': [3, 4, 5, 7, 10, 13, 15, 18],\n",
    "        'alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 0.6, 0.8]\n",
    "    },\n",
    "    \n",
    "    'LinearSVC': {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'loss': ['hinge', 'squared_hinge'],\n",
    "        'dual': [True, False],\n",
    "        'tol': [0.00001, 0.00005, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "        'C': [0.1, 0.5, 1.0, 1.3, 1.5, 2.0],\n",
    "        'multi_class': ['ovr', 'crammer_singer'],\n",
    "        'fit_intercept': [True, False]\n",
    "    },\n",
    "    \n",
    "    'LogisticRegressionCV': {\n",
    "        'Cs': [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000, 5000, 8000],\n",
    "        'fit_intercept': [True, False],\n",
    "        'cv': [2, 3, 4, 5, 6, 7],\n",
    "        'dual': [True, False],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        'tol': [0.00001, 0.00005, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    },\n",
    "    \n",
    "    'MLPClassifier': {\n",
    "        'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'alpha': [0.000001, 0.00001, 0.0001, 0.0005, 0.001, 0.01, 0.1, 0.5],\n",
    "        'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "        'learning_rate_init': [0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 0.7, 0.8, 1.0]\n",
    "    },\n",
    "    \n",
    "    'MultinomialNB': {\n",
    "        'alpha': [0.01, 0.1, 0.5, 1.0, 1.5, 1.8, 2.1],\n",
    "        'fit_prior': [True, False]\n",
    "    },\n",
    "    \n",
    "    'PassiveAggressiveClassifier': {\n",
    "        'C': [0.5, 1.0, 1.4, 1.8, 2.0, 2.5],\n",
    "        'fit_intercept': [True, False],\n",
    "        'tol': [0.00001, 0.00005, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "        'early_stopping': [True, False]\n",
    "    },\n",
    "    \n",
    "    'Perceptron': {\n",
    "        'penalty': [None, 'l1', 'l2', 'elasticnet'],\n",
    "        'alpha': [0.000001, 0.00001, 0.0001, 0.0005, 0.001, 0.01, 0.1, 0.5],\n",
    "        'fit_intercept': [True, False],\n",
    "        'tol': [0.00001, 0.00005, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    },\n",
    "    \n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [3, 5, 10, 15, 20, 25, 30],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'min_impurity_split': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3],\n",
    "        'bootstrap': [True, False],\n",
    "        'oob_score': [True, False]\n",
    "    },\n",
    "    \n",
    "\n",
    "    \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
